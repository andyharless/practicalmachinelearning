
> # READ AND PROCESS INPUT DATA
> 
> # Read in data.
> library(readr)

> pml_training <- read_csv("pml-training.csv")

> data1 <- as.data.frame(pml_training)

> # Most of the columns are summary statistics, which are NA for most individual rows.
> # Get rid of them.
> goodcols <- !is.na(data1[1,])

> data1 <- data1[,goodcols]

> pml_data <- data1[,8:ncol(data1)]

> # Check for rows that still have missing data.
> sum(is.na(pml_data))
[1] 3

> # Not much remaining missing data, so let's just eliminate those cases.
> goodrows = rowSums(is.na(pml_data))==0

> pml = pml_data[goodrows,]

> dim(pml)
[1] 19621    53

> head(pml)
  roll_belt pitch_belt yaw_belt total_accel_belt gyros_belt_x gyros_belt_y gyros_belt_z
1      1.41       8.07    -94.4                3         0.00         0.00        -0.02
2      1.41       8.07    -94.4                3         0.02         0.00        -0.02
3      1.42       8.07    -94.4                3         0.00         0.00        -0.02
4      1.48       8.05    -94.4                3         0.02         0.00        -0.03
5      1.48       8.07    -94.4                3         0.02         0.02        -0.02
6      1.45       8.06    -94.4                3         0.02         0.00        -0.02
  accel_belt_x accel_belt_y accel_belt_z magnet_belt_x magnet_belt_y magnet_belt_z
1          -21            4           22            -3           599          -313
2          -22            4           22            -7           608          -311
3          -20            5           23            -2           600          -305
4          -22            3           21            -6           604          -310
5          -21            2           24            -6           600          -302
6          -21            4           21             0           603          -312
  roll_arm pitch_arm yaw_arm total_accel_arm gyros_arm_x gyros_arm_y gyros_arm_z
1     -128      22.5    -161              34        0.00        0.00       -0.02
2     -128      22.5    -161              34        0.02       -0.02       -0.02
3     -128      22.5    -161              34        0.02       -0.02       -0.02
4     -128      22.1    -161              34        0.02       -0.03        0.02
5     -128      22.1    -161              34        0.00       -0.03        0.00
6     -128      22.0    -161              34        0.02       -0.03        0.00
  accel_arm_x accel_arm_y accel_arm_z magnet_arm_x magnet_arm_y magnet_arm_z
1        -288         109        -123         -368          337          516
2        -290         110        -125         -369          337          513
3        -289         110        -126         -368          344          513
4        -289         111        -123         -372          344          512
5        -289         111        -123         -374          337          506
6        -289         111        -122         -369          342          513
  roll_dumbbell pitch_dumbbell yaw_dumbbell total_accel_dumbbell gyros_dumbbell_x
1      13.05217      -70.49400    -84.87394                   37                0
2      13.13074      -70.63751    -84.71065                   37                0
3      12.85075      -70.27812    -85.14078                   37                0
4      13.43120      -70.39379    -84.87363                   37                0
5      13.37872      -70.42856    -84.85306                   37                0
6      13.38246      -70.81759    -84.46500                   37                0
  gyros_dumbbell_y gyros_dumbbell_z accel_dumbbell_x accel_dumbbell_y accel_dumbbell_z
1            -0.02             0.00             -234               47             -271
2            -0.02             0.00             -233               47             -269
3            -0.02             0.00             -232               46             -270
4            -0.02            -0.02             -232               48             -269
5            -0.02             0.00             -233               48             -270
6            -0.02             0.00             -234               48             -269
  magnet_dumbbell_x magnet_dumbbell_y magnet_dumbbell_z roll_forearm pitch_forearm
1              -559               293               -65         28.4         -63.9
2              -555               296               -64         28.3         -63.9
3              -561               298               -63         28.3         -63.9
4              -552               303               -60         28.1         -63.9
5              -554               292               -68         28.0         -63.9
6              -558               294               -66         27.9         -63.9
  yaw_forearm total_accel_forearm gyros_forearm_x gyros_forearm_y gyros_forearm_z
1        -153                  36            0.03            0.00           -0.02
2        -153                  36            0.02            0.00           -0.02
3        -152                  36            0.03           -0.02            0.00
4        -152                  36            0.02           -0.02            0.00
5        -152                  36            0.02            0.00           -0.02
6        -152                  36            0.02           -0.02           -0.03
  accel_forearm_x accel_forearm_y accel_forearm_z magnet_forearm_x magnet_forearm_y
1             192             203            -215              -17              654
2             192             203            -216              -18              661
3             196             204            -213              -18              658
4             189             206            -214              -16              658
5             189             206            -214              -17              655
6             193             203            -215               -9              660
  magnet_forearm_z classe
1              476      A
2              473      A
3              469      A
4              469      A
5              473      A
6              478      A

> # Divide data into training, cross-validation, and test sets
> library("caret")

> set.seed(999)

> inTrain <- createDataPartition(y=pml$classe, p=0.8, list=FALSE)

> training <- pml[inTrain,]

> testing <- pml[-inTrain,]

> inTrain1 <- createDataPartition(y=training$classe, p=0.75, list=FALSE)

> train1 <- training[inTrain1,]

> validate <- training[-inTrain1,]

> # FIT THE MODELS ON THE INITIAL TRAINING SET
> 
> # Set up to run fits on multiple cores
> library(parallel)

> library(doParallel)

> cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS

> registerDoParallel(cluster)

> # Train the models
> modelnames = c("lda", "qda", "rda", "rf", "nnet", "pcaNNet", "AdaBag",
+             "svmRadial", "multinom", "kknn")

> modelfits = list()

> for (m in modelnames) {
+      print ( paste("Training model:", m) )
+      fit <- train(classe ~., data=train1, method=m, 
+                   preP .... [TRUNCATED] 
[1] "Training model: lda"
[1] "Training model: qda"
[1] "Training model: rda"
[1] "Training model: rf"
[1] "Training model: nnet"
# weights:  295
initial  value 19943.346617 
iter  10 value 18697.767657
iter  20 value 18697.723351
final  value 18697.722859 
converged
[1] "Training model: pcaNNet"
# weights:  220
initial  value 16926.660917 
iter  10 value 11861.438782
iter  20 value 11529.932859
iter  30 value 9872.740994
iter  40 value 9034.869308
iter  50 value 8370.731026
iter  60 value 7793.321202
iter  70 value 7021.387689
iter  80 value 6435.287576
iter  90 value 6141.753615
iter 100 value 5899.285315
final  value 5899.285315 
stopped after 100 iterations
[1] "Training model: AdaBag"
[1] "Training model: svmRadial"
[1] "Training model: multinom"
# weights:  270 (212 variable)
initial  value 18952.740857 
iter  10 value 15335.498593
iter  20 value 13557.255823
iter  30 value 12710.958349
iter  40 value 12047.436607
iter  50 value 11585.218165
iter  60 value 11299.055709
iter  70 value 11134.365813
iter  80 value 11028.614944
iter  90 value 10972.054438
iter 100 value 10911.096350
final  value 10911.096350 
stopped after 100 iterations
[1] "Training model: kknn"

> # End parallel processing environment
> stopCluster(cluster)

> registerDoSEQ()

> # Clean up environment
> rm(data1)

> rm(pml_data)

> rm(pml_training)

> # EVALUTE MODELS (INCLUDING "VOTED" MODEL) ON VALIDATION SET
> 
> # Predict for validation set
> confuse <- list()

> predicted <- list()

> for (f in modelfits) {
+     writeLines ( paste("\n\n\nPredicting validation set for model:", f[[1]]) )
+     p <- predict(f, newdata=validate)
+    .... [TRUNCATED] 



Predicting validation set for model: lda
Confusion Matrix and Statistics

          Reference
Prediction   A   B   C   D   E
         A 890 108  61  31  34
         B  30 496  67  24 123
         C  90  94 435  86  65
         D 102  25  94 478  76
         E   4  36  27  24 423

Overall Statistics
                                          
               Accuracy : 0.6939          
                 95% CI : (0.6792, 0.7083)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.6131          
 Mcnemar's Test P-Value : < 2.2e-16       

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.7975   0.6535   0.6360   0.7434   0.5867
Specificity            0.9166   0.9229   0.8966   0.9095   0.9716
Pos Pred Value         0.7918   0.6703   0.5649   0.6168   0.8230
Neg Pred Value         0.9193   0.9174   0.9210   0.9476   0.9126
Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2269   0.1264   0.1109   0.1218   0.1078
Detection Prevalence   0.2865   0.1886   0.1963   0.1976   0.1310
Balanced Accuracy      0.8571   0.7882   0.7663   0.8264   0.7791



Predicting validation set for model: qda
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1063   46    0    2    0
         B   33  641   29    0   21
         C    8   64  645  104   42
         D    8    2    4  530   18
         E    4    6    6    7  640

Overall Statistics
                                          
               Accuracy : 0.897           
                 95% CI : (0.8871, 0.9064)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.8698          
 Mcnemar's Test P-Value : < 2.2e-16       

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9525   0.8445   0.9430   0.8243   0.8877
Specificity            0.9829   0.9738   0.9327   0.9902   0.9928
Pos Pred Value         0.9568   0.8854   0.7474   0.9431   0.9653
Neg Pred Value         0.9812   0.9631   0.9873   0.9664   0.9752
Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2710   0.1634   0.1644   0.1351   0.1631
Detection Prevalence   0.2832   0.1846   0.2200   0.1433   0.1690
Balanced Accuracy      0.9677   0.9091   0.9378   0.9073   0.9402



Predicting validation set for model: rda
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1063   46    0    2    0
         B   33  641   29    0   21
         C    8   64  645  104   42
         D    8    2    4  530   18
         E    4    6    6    7  640

Overall Statistics
                                          
               Accuracy : 0.897           
                 95% CI : (0.8871, 0.9064)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.8698          
 Mcnemar's Test P-Value : < 2.2e-16       

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9525   0.8445   0.9430   0.8243   0.8877
Specificity            0.9829   0.9738   0.9327   0.9902   0.9928
Pos Pred Value         0.9568   0.8854   0.7474   0.9431   0.9653
Neg Pred Value         0.9812   0.9631   0.9873   0.9664   0.9752
Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2710   0.1634   0.1644   0.1351   0.1631
Detection Prevalence   0.2832   0.1846   0.2200   0.1433   0.1690
Balanced Accuracy      0.9677   0.9091   0.9378   0.9073   0.9402



Predicting validation set for model: rf
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1116    7    0    0    0
         B    0  750    4    0    0
         C    0    2  677   12    4
         D    0    0    3  630    3
         E    0    0    0    1  714

Overall Statistics
                                          
               Accuracy : 0.9908          
                 95% CI : (0.9873, 0.9936)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9884          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            1.0000   0.9881   0.9898   0.9798   0.9903
Specificity            0.9975   0.9987   0.9944   0.9982   0.9997
Pos Pred Value         0.9938   0.9947   0.9741   0.9906   0.9986
Neg Pred Value         1.0000   0.9972   0.9978   0.9960   0.9978
Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2845   0.1912   0.1726   0.1606   0.1820
Detection Prevalence   0.2863   0.1922   0.1772   0.1621   0.1823
Balanced Accuracy      0.9988   0.9934   0.9921   0.9890   0.9950



Predicting validation set for model: nnet
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1116  759  684  643  721
         B    0    0    0    0    0
         C    0    0    0    0    0
         D    0    0    0    0    0
         E    0    0    0    0    0

Overall Statistics
                                          
               Accuracy : 0.2845          
                 95% CI : (0.2704, 0.2989)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : 0.506           
                                          
                  Kappa : 0               
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            1.0000   0.0000   0.0000   0.0000   0.0000
Specificity            0.0000   1.0000   1.0000   1.0000   1.0000
Pos Pred Value         0.2845      NaN      NaN      NaN      NaN
Neg Pred Value            NaN   0.8065   0.8256   0.8361   0.8162
Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2845   0.0000   0.0000   0.0000   0.0000
Detection Prevalence   1.0000   0.0000   0.0000   0.0000   0.0000
Balanced Accuracy      0.5000   0.5000   0.5000   0.5000   0.5000



Predicting validation set for model: pcaNNet
Confusion Matrix and Statistics

          Reference
Prediction   A   B   C   D   E
         A 880  70  52  14  32
         B  10 340  27  15  91
         C 100 121 484  98  79
         D 107 107  45 432  83
         E  19 121  76  84 436

Overall Statistics
                                          
               Accuracy : 0.6556          
                 95% CI : (0.6405, 0.6705)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.5664          
 Mcnemar's Test P-Value : < 2.2e-16       

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.7885  0.44796   0.7076   0.6719   0.6047
Specificity            0.9401  0.95480   0.8771   0.8957   0.9063
Pos Pred Value         0.8397  0.70393   0.5488   0.5581   0.5924
Neg Pred Value         0.9179  0.87820   0.9342   0.9330   0.9106
Prevalence             0.2845  0.19347   0.1744   0.1639   0.1838
Detection Rate         0.2243  0.08667   0.1234   0.1101   0.1111
Detection Prevalence   0.2671  0.12312   0.2248   0.1973   0.1876
Balanced Accuracy      0.8643  0.70138   0.7924   0.7838   0.7555



Predicting validation set for model: AdaBag
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1100  489  661  533  312
         B   16  270   23  110   98
         C    0    0    0    0    0
         D    0    0    0    0    0
         E    0    0    0    0  311

Overall Statistics
                                          
               Accuracy : 0.4285          
                 95% CI : (0.4129, 0.4442)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.223           
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9857  0.35573   0.0000   0.0000  0.43135
Specificity            0.2893  0.92193   1.0000   1.0000  1.00000
Pos Pred Value         0.3554  0.52224      NaN      NaN  1.00000
Neg Pred Value         0.9807  0.85643   0.8256   0.8361  0.88649
Prevalence             0.2845  0.19347   0.1744   0.1639  0.18379
Detection Rate         0.2804  0.06882   0.0000   0.0000  0.07928
Detection Prevalence   0.7889  0.13179   0.0000   0.0000  0.07928
Balanced Accuracy      0.6375  0.63883   0.5000   0.5000  0.71567



Predicting validation set for model: svmRadial
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1106   59    3    3    0
         B    5  669   21    0    6
         C    5   30  631   89   33
         D    0    0   24  549   20
         E    0    1    5    2  662

Overall Statistics
                                          
               Accuracy : 0.922           
                 95% CI : (0.9132, 0.9302)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9012          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9910   0.8814   0.9225   0.8538   0.9182
Specificity            0.9768   0.9899   0.9515   0.9866   0.9975
Pos Pred Value         0.9445   0.9544   0.8008   0.9258   0.9881
Neg Pred Value         0.9964   0.9721   0.9831   0.9718   0.9819
Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2819   0.1705   0.1608   0.1399   0.1687
Detection Prevalence   0.2985   0.1787   0.2009   0.1512   0.1708
Balanced Accuracy      0.9839   0.9357   0.9370   0.9202   0.9578



Predicting validation set for model: multinom
Confusion Matrix and Statistics

          Reference
Prediction   A   B   C   D   E
         A 915 129 118  49  62
         B  52 421  82  59 139
         C  56  86 351  83  59
         D  86  58 103 431  72
         E   7  65  30  21 389

Overall Statistics
                                          
               Accuracy : 0.6391          
                 95% CI : (0.6238, 0.6541)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.5414          
 Mcnemar's Test P-Value : < 2.2e-16       

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.8199   0.5547  0.51316   0.6703  0.53953
Specificity            0.8725   0.8951  0.91232   0.9027  0.96159
Pos Pred Value         0.7188   0.5591  0.55276   0.5747  0.75977
Neg Pred Value         0.9242   0.8934  0.89872   0.9332  0.90267
Prevalence             0.2845   0.1935  0.17436   0.1639  0.18379
Detection Rate         0.2332   0.1073  0.08947   0.1099  0.09916
Detection Prevalence   0.3245   0.1919  0.16187   0.1912  0.13051
Balanced Accuracy      0.8462   0.7249  0.71274   0.7865  0.75056



Predicting validation set for model: kknn
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1110    5    0    0    0
         B    2  745    1    0    5
         C    3    6  675   13    3
         D    0    3    5  628    6
         E    1    0    3    2  707

Overall Statistics
                                          
               Accuracy : 0.9852          
                 95% CI : (0.9809, 0.9888)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9813          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9946   0.9816   0.9868   0.9767   0.9806
Specificity            0.9982   0.9975   0.9923   0.9957   0.9981
Pos Pred Value         0.9955   0.9894   0.9643   0.9782   0.9916
Neg Pred Value         0.9979   0.9956   0.9972   0.9954   0.9956
Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2829   0.1899   0.1721   0.1601   0.1802
Detection Prevalence   0.2842   0.1919   0.1784   0.1637   0.1817
Balanced Accuracy      0.9964   0.9895   0.9896   0.9862   0.9894

> kappas <- sapply(confuse, function(co) co[[3]]["Kappa"])

> names(kappas) <- modelnames

> names(confuse) <- modelnames

> names(predicted) <- modelnames

> bestmods <- names(sort(kappas,decreasing=TRUE)[1:3])

> print(bestmods)  # 3 best models
[1] "rf"        "kknn"      "svmRadial"

> # Calculate "voted" predictions, giving best model an extra tie-breaking vote.
> choices = c()

> m = length(validate$classe)

> for (i in 1:m) {
+     p1 <- unlist(predicted[bestmods[[1]]])[[i]]
+     p2 <- unlist(predicted[bestmods[[2]]])[[i]]
+     p3 <- unlist(predicted[be .... [TRUNCATED] 

> choices = as.factor(choices)

> confuse_voted_1stpass = confusionMatrix(choices, validate$classe)

> confuse_voted_1stpass
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1116    6    0    0    0
         B    0  749    3    0    0
         C    0    4  679   16    5
         D    0    0    0  626    4
         E    0    0    2    1  712

Overall Statistics
                                          
               Accuracy : 0.9895          
                 95% CI : (0.9858, 0.9925)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9868          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            1.0000   0.9868   0.9927   0.9736   0.9875
Specificity            0.9979   0.9991   0.9923   0.9988   0.9991
Pos Pred Value         0.9947   0.9960   0.9645   0.9937   0.9958
Neg Pred Value         1.0000   0.9968   0.9984   0.9948   0.9972
Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2845   0.1909   0.1731   0.1596   0.1815
Detection Prevalence   0.2860   0.1917   0.1795   0.1606   0.1823
Balanced Accuracy      0.9989   0.9929   0.9925   0.9862   0.9933

> confuse["rf"]
$rf
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1116    7    0    0    0
         B    0  750    4    0    0
         C    0    2  677   12    4
         D    0    0    3  630    3
         E    0    0    0    1  714

Overall Statistics
                                          
               Accuracy : 0.9908          
                 95% CI : (0.9873, 0.9936)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9884          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            1.0000   0.9881   0.9898   0.9798   0.9903
Specificity            0.9975   0.9987   0.9944   0.9982   0.9997
Pos Pred Value         0.9938   0.9947   0.9741   0.9906   0.9986
Neg Pred Value         1.0000   0.9972   0.9978   0.9960   0.9978
Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2845   0.1912   0.1726   0.1606   0.1820
Detection Prevalence   0.2863   0.1922   0.1772   0.1621   0.1823
Balanced Accuracy      0.9988   0.9934   0.9921   0.9890   0.9950


> # Here make a decision.
> # The decision is to defer the "voted vs RF" decision to the next evaluation step.
> 
> 
> # RE-FIT BEST MODELS INCLUDING  .... [TRUNCATED] 

> registerDoParallel(cluster)

> # Go through the 3 best models and re-fit including original validation data
> set.seed(998)

> fits = list()

> for (m in bestmods) {
+   print ( paste("Training model:", m) )
+   fit <- train(classe ~., data=training, method=m, 
+                preProcess="B ..." ... [TRUNCATED] 
[1] "Training model: rf"
[1] "Training model: kknn"
[1] "Training model: svmRadial"

> # End parallel processing environment
> stopCluster(cluster)

> registerDoSEQ()

> # EVALUATE MODELS ON INITIAL TEST SET
> 
> # Predict for initial test set
> conf <- list()

> pred <- list()

> for (f in fits) {
+   writeLines ( paste("\n\n\nPredicting initial test set for model:", f[[1]]) )
+   p <- predict(f, newdata=testing)
+   pred <-  .... [TRUNCATED] 



Predicting initial test set for model: rf
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1113    4    0    0    0
         B    1  754    4    0    0
         C    1    1  679    2    1
         D    0    0    1  640    0
         E    0    0    0    1  720

Overall Statistics
                                          
               Accuracy : 0.9959          
                 95% CI : (0.9934, 0.9977)
    No Information Rate : 0.2843          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9948          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9982   0.9934   0.9927   0.9953   0.9986
Specificity            0.9986   0.9984   0.9985   0.9997   0.9997
Pos Pred Value         0.9964   0.9934   0.9927   0.9984   0.9986
Neg Pred Value         0.9993   0.9984   0.9985   0.9991   0.9997
Prevalence             0.2843   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2838   0.1922   0.1731   0.1632   0.1836
Detection Prevalence   0.2848   0.1935   0.1744   0.1634   0.1838
Balanced Accuracy      0.9984   0.9959   0.9956   0.9975   0.9992



Predicting initial test set for model: kknn
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1110    4    1    0    0
         B    2  749    2    0    5
         C    1    6  679    2    2
         D    2    0    1  640    1
         E    0    0    1    1  713

Overall Statistics
                                          
               Accuracy : 0.9921          
                 95% CI : (0.9888, 0.9946)
    No Information Rate : 0.2843          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.99            
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9955   0.9868   0.9927   0.9953   0.9889
Specificity            0.9982   0.9972   0.9966   0.9988   0.9994
Pos Pred Value         0.9955   0.9881   0.9841   0.9938   0.9972
Neg Pred Value         0.9982   0.9968   0.9985   0.9991   0.9975
Prevalence             0.2843   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2830   0.1910   0.1731   0.1632   0.1818
Detection Prevalence   0.2843   0.1933   0.1759   0.1642   0.1823
Balanced Accuracy      0.9969   0.9920   0.9946   0.9971   0.9941



Predicting initial test set for model: svmRadial
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1110   62    0    2    0
         B    1  679   31    1    5
         C    3   18  639   55   15
         D    0    0    8  583   27
         E    1    0    6    2  674

Overall Statistics
                                          
               Accuracy : 0.9396          
                 95% CI : (0.9317, 0.9468)
    No Information Rate : 0.2843          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9234          
 Mcnemar's Test P-Value : < 2.2e-16       

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9955   0.8946   0.9342   0.9067   0.9348
Specificity            0.9772   0.9880   0.9719   0.9893   0.9972
Pos Pred Value         0.9455   0.9470   0.8753   0.9434   0.9868
Neg Pred Value         0.9982   0.9750   0.9859   0.9818   0.9855
Prevalence             0.2843   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2830   0.1731   0.1629   0.1486   0.1719
Detection Prevalence   0.2993   0.1828   0.1861   0.1576   0.1741
Balanced Accuracy      0.9864   0.9413   0.9531   0.9480   0.9660

> bestkappas <- sapply(conf, function(co) co[[3]]["Kappa"])

> names(bestkappas) <- bestmods

> names(conf) <- bestmods

> names(pred) <- bestmods

> # Calculate "Voted" predictions for initial test set
> voted = c()

> m = length(testing$classe)

> for (i in 1:m) {
+     p1 <- unlist(pred[bestmods[[1]]])[[i]]
+     p2 <- unlist(pred[bestmods[[2]]])[[i]]
+     p3 <- unlist(pred[bestmods[[3]]])[[ .... [TRUNCATED] 

> voted = as.factor(voted)

> confuse_voted_2ndpass = confusionMatrix(voted, testing$classe)

> save( confuse, conf, confuse_voted_1stpass, confuse_voted_2ndpass, file="confusion.dat" )

> confuse_voted_2ndpass
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1115    6    0    0    0
         B    0  750    5    0    0
         C    0    3  679    3    3
         D    0    0    0  639    0
         E    0    0    0    1  718

Overall Statistics
                                          
               Accuracy : 0.9946          
                 95% CI : (0.9918, 0.9967)
    No Information Rate : 0.2843          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9932          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            1.0000   0.9881   0.9927   0.9938   0.9958
Specificity            0.9979   0.9984   0.9972   1.0000   0.9997
Pos Pred Value         0.9946   0.9934   0.9869   1.0000   0.9986
Neg Pred Value         1.0000   0.9972   0.9985   0.9988   0.9991
Prevalence             0.2843   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2843   0.1912   0.1731   0.1629   0.1831
Detection Prevalence   0.2858   0.1925   0.1754   0.1629   0.1833
Balanced Accuracy      0.9989   0.9933   0.9950   0.9969   0.9978

> conf["rf"]
$rf
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1113    4    0    0    0
         B    1  754    4    0    0
         C    1    1  679    2    1
         D    0    0    1  640    0
         E    0    0    0    1  720

Overall Statistics
                                          
               Accuracy : 0.9959          
                 95% CI : (0.9934, 0.9977)
    No Information Rate : 0.2843          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9948          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9982   0.9934   0.9927   0.9953   0.9986
Specificity            0.9986   0.9984   0.9985   0.9997   0.9997
Pos Pred Value         0.9964   0.9934   0.9927   0.9984   0.9986
Neg Pred Value         0.9993   0.9984   0.9985   0.9991   0.9997
Prevalence             0.2843   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2838   0.1922   0.1731   0.1632   0.1836
Detection Prevalence   0.2848   0.1935   0.1744   0.1634   0.1838
Balanced Accuracy      0.9984   0.9959   0.9956   0.9975   0.9992


> # Here make a decision.
> # The decision is to use the RF model and throw out the others.
> 
> 
> # FIT BEST MODEL ON FULL DATA SET
> 
> # Set up to .... [TRUNCATED] 

> library(doParallel)

> cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS

> registerDoParallel(cluster)

> # Fit the best model
> fit <- train(classe ~., data=pml, method="rf", preProcess="BoxCox", allowParallel=TRUE)

> # End parallel processing environment
> stopCluster(cluster)

> registerDoSEQ()

> # GENERATE PREDICTIONS FOR UNLABELLED TEST DATA
> 
> # Read in unlabelled test cases.
> pml_testing <- read_csv("pml-testing.csv")

> data2 <- as.data.frame(pml_testing)

> # Most of the columns are summary statistics, which are NA for most individual rows.
> # Get rid of them.
> goodcols <- !is.na(data2[1,])

> data2 <- data2[,goodcols]

> pml_testdata <- data2[,8:ncol(data2)]

> # Predict the test cases
> p <- predict(fit, newdata=pml_testdata)

> sink()
